{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/run-llama/llama_parse\n",
    "\n",
    "https://cloud.llamaindex.ai/parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stages of RAG and our approach\n",
    "https://docs.llamaindex.ai/en/stable/getting_started/concepts.html\n",
    "\n",
    "* Loading - getting data from where it is currently into our pipeline\n",
    "    * Connectors - aka Readers; used to ingest data from any source and formats into Documents & Nodes - **we're using Llamaparse**\n",
    "    * Documents & Nodes - Documents are a generic container around any data source; Node is a chunk of a source `Document`. **not done separately for us**\n",
    "* Indexing - structured format for easy retrieval; `VectorStoreIndex` does all of the above\n",
    "    * Indexes - Data stored in format easy to retrieve, usually vector embeddings; can be stored in a vector store\n",
    "    * Embeddings - Numerical representations of data; query embeddings are matched using similarity matching. Use embedding models to create this\n",
    "* Querying - Ask questions and get responses -**we use query engine**\n",
    "    * Retrievers - Retrieve relevant context\n",
    "    * Router - Which retriever is used\n",
    "    * Node Postprocessor - Apply transformations, filters and re-ranking logic to retrieved nodes\n",
    "    * Response Synthesiser - Generates response from LLM using query and retrieved chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found\n"
     ]
    }
   ],
   "source": [
    "LLAMAPARSE_API_KEY = os.environ.get('LLAMAPARSE_API_KEY')\n",
    "if LLAMAPARSE_API_KEY is not None:\n",
    "    print('API key found')\n",
    "else:\n",
    "    print('Check for API key in environment variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate parser\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMAPARSE_API_KEY,\n",
    "    result_type=\"markdown\", # or text\n",
    "    # num_workers=4 # for multiple files\n",
    "    verbose=True,\n",
    "    language=\"en\", # default is english\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 449fa1cc-a281-47dd-836b-ade1d6736062\n"
     ]
    }
   ],
   "source": [
    "# load document and parse it \n",
    "documents = parser.load_data('../data/1910.13461.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 97a15eaa-0826-4e06-85b2-07d99a42b453\n"
     ]
    }
   ],
   "source": [
    "# read in and parse pdf file in documents format\n",
    "file_extractor = {\".pdf\": parser}\n",
    "reader = SimpleDirectoryReader(input_files=['../data/1910.13461.pdf'], file_extractor=file_extractor)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into nodes and create an index from parsed markdown\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# create query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 of BART for different datasets are as follows:\n",
      "- ELI5 dataset: 30.6\n",
      "- CNN/DailyMail dataset: 44.16\n",
      "- XSum dataset: 45.14\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about R1 of bart for different datasets\"\n",
    "\n",
    "resp = query_engine.query(query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization, Dialogue response generation, Abstractive QA, Translation\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"list all the tasks that work with bart\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 74d94431-e2f3-4a2e-9c12-b830f0aee605\n"
     ]
    }
   ],
   "source": [
    "# load document and parse it \n",
    "documents = parser.load_data('../data/axis-press-release-q3fy24.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into nodes and create an index from parsed markdown\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# create query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amitabh Chaudhry, MD&CEO of Axis Bank, mentioned that India is being looked upon as an important investment destination and that the Indian economic momentum has been strong. He emphasized that Axis Bank's focus is on sustainable and inclusive growth, with the customer being at the center of every discussion. He also mentioned the celebration of 'Sparsh Week', which involved educative customer-centric activities across multiple branches and retail asset centers, reaching out to a large number of employees.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"summarize comments made by amitabh chaudhry?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.gopubby.com/llamaparse-rag-beats-all-comers-60948c6cc0e4\n",
    "\n",
    "#### Using MarkdownElementNodeParser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
