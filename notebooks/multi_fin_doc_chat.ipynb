{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found\n"
     ]
    }
   ],
   "source": [
    "# check for llamaparse key\n",
    "LLAMAPARSE_API_KEY = os.environ.get('LLAMAPARSE_API_KEY')\n",
    "if LLAMAPARSE_API_KEY is not None:\n",
    "    print('API key found')\n",
    "else:\n",
    "    print('Check for API key in environment variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(3, 11), match='-q1fy24.'>\n",
      "<re.Match object; span=(4, 10), match='q1fy24'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'q1fy24'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "\n",
    "re_dash_to_dot = re.compile(r\"-([^\\.]+)\\.\")\n",
    "print(re.search(re_dash_to_dot, file_list[0]))\n",
    "print(re.search(pattern, file_list[0]))\n",
    "re.search(pattern, file_list[0]).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufr-q1fy24.pdf', 'ufr-q3fy24.pdf', 'ufr-q2fy24.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of files over which to prep\n",
    "file_list = [file for file in os.listdir('../data') if file.startswith('ufr')]\n",
    "file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of variables over which to construct the indexes\n",
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "doc_names = ['axis-'+re.search(pattern, file).group() for file in file_list]\n",
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24-index', 'axis-q3fy24-index', 'axis-q2fy24-index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of variables over which to construct the indexes\n",
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "vec_index_list = ['axis-'+re.search(pattern, file).group()+'-index' for file in file_list]\n",
    "vec_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fy24', 'fy24', 'fy24']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\\w{4}(?=\\.)\"\n",
    "year = [re.search(pattern, file).group() for file in file_list]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q1', 'q3', 'q2']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(?<=-)\\w{2}\"\n",
    "quarter = [re.search(pattern, file).group() for file in file_list]\n",
    "quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate parser\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMAPARSE_API_KEY,\n",
    "    result_type=\"markdown\", # or text\n",
    "    num_workers=4, # for multiple files\n",
    "    verbose=True,\n",
    "    language=\"en\", # default is english\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename as metadata\n",
    "file_extractor = {\".pdf\": parser}\n",
    "filename_fn = lambda filename: {\"file_name\": filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufr-q1fy24.pdf', 'ufr-q3fy24.pdf', 'ufr-q2fy24.pdf']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9796c9f8-fa86-478e-ada4-060ff0a77314\n",
      "..Started parsing the file under job_id 161c555f-c8a1-49af-82bd-11021f780e5d\n",
      "..Started parsing the file under job_id b5d71922-a164-4298-9b6f-3b70910d8fdb\n",
      "..."
     ]
    }
   ],
   "source": [
    "# read in docs\n",
    "doc_dict = {}\n",
    "\n",
    "for file, doc_name, qtr, yr in zip(file_list, doc_names, quarter, year):\n",
    "    reader = SimpleDirectoryReader(\n",
    "        input_files=['../data/' + file],\n",
    "        file_extractor=file_extractor,\n",
    "        # filename_as_id=True,\n",
    "        file_metadata=filename_fn,\n",
    "        )\n",
    "    doc = reader.load_data()\n",
    "    for i in doc:\n",
    "        i.metadata['file_descr']=f'Axis bank quarterly earnings report for {re.search(pattern, file).group()} '\n",
    "        i.metadata['financial year']=yr,\n",
    "        i.metadata['quarter']=qtr,\n",
    "    doc_dict[doc_name] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(variable, expected_length):\n",
    "    try:\n",
    "        if len(variable)==len(expected_length):\n",
    "            print('All files parsed')\n",
    "        else:\n",
    "            raise ValueError(f'Number of files parse is not equal to {len(expected_length)}')\n",
    "    except ValueError as e:\n",
    "        print(f'Caught Exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files parsed\n"
     ]
    }
   ],
   "source": [
    "check_length(doc_dict, file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more imports\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    "    )\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate llm and markdown parser\n",
    "llm = OpenAI(model='gpt-3.5-turbo-0125', temperature=0.1)\n",
    "node_parser=MarkdownElementNodeParser(llm=llm)\n",
    "storage_context = StorageContext.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/axis_qr_index\n",
      "data path exists\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(f'../data/axis_qr_index')\n",
    "\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)\n",
    "    print(data_path)\n",
    "    print('data path created')\n",
    "else:\n",
    "    print(data_path)\n",
    "    print('data path exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 3953.66it/s]\n",
      "100%|██████████| 15/15 [00:16<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q1fy24 indexed and stored successfully to disk\n",
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 19127.12it/s]\n",
      "100%|██████████| 21/21 [00:17<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q3fy24 indexed and stored successfully to disk\n",
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 10157.67it/s]\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q2fy24 indexed and stored successfully to disk\n"
     ]
    }
   ],
   "source": [
    "# loop over the doc_list dictionary to parse the documents, construct vector index and store to disk\n",
    "for doc in doc_dict.keys():\n",
    "    # print(doc)\n",
    "    documents = doc_dict[doc]\n",
    "    # run parser and get nodes for text and summary for tables\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "    index = VectorStoreIndex(nodes=base_nodes+objects, storage_context=storage_context)\n",
    "    index.set_index_id(doc)\n",
    "    index.storage_context.persist(persist_dir=f'../data/axis_qr_index')\n",
    "    print(f'{doc} indexed and stored successfully to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded index axis-q1fy24 from local storage\n",
      "loaded index axis-q3fy24 from local storage\n",
      "loaded index axis-q2fy24 from local storage\n"
     ]
    }
   ],
   "source": [
    "# load stored index \n",
    "local_index= {}\n",
    "for name in doc_names:   \n",
    "    storage_context=StorageContext.from_defaults(\n",
    "        persist_dir=f'../data/axis_qr_index')\n",
    "    cur_index=load_index_from_storage(storage_context, index_id=name)\n",
    "    local_index[name]=cur_index\n",
    "    print(f'loaded index {name} from local storage')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://docs.llamaindex.ai/en/stable/module_guides/storing/customization/\n",
    "# # loop over the variable list and document dictionary to parse the nodes and construct indexes\n",
    "# for file_list_item, vec_index_list_item in zip(file_list, vec_index_list):\n",
    "    \n",
    "#     # store vector index to disk\n",
    "#     data_path = Path(f'../data/axis_qr_index/{vec_index_list_item}')\n",
    "#     # print(data_path)\n",
    "#     if not data_path.exists():\n",
    "#         Path.mkdir(data_path, parents=True, exist_ok=True)\n",
    "#         # print(data_path)\n",
    "    \n",
    "#     documents = doc_list[file_list_item]\n",
    "#     # run parser and get nodes for text and summary for tables\n",
    "#     nodes = node_parser.get_nodes_from_documents(documents)\n",
    "#     base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "#     index = VectorStoreIndex(nodes=base_nodes+objects, storage_context=storage_context)\n",
    "    \n",
    "#     index.storage_context.persist(persist_dir=data_path)\n",
    "#     print(f'{file_list_item} indexed and stored successfully to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurdeep/miniconda3/envs/streamchat/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# vector store imports\n",
    "# !pip install llama-index-vector-stores-pinecone\n",
    "# !pip install pinecone-client\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pc = Pinecone()\n",
    "\n",
    "# dictionary of indexes\n",
    "pc_index_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 1536,\n",
       "              'host': 'axis-q1fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'axis-q1fy24-index',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}},\n",
       "             {'dimension': 1536,\n",
       "              'host': 'axis-q2fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'axis-q2fy24-index',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}},\n",
       "             {'dimension': 1536,\n",
       "              'host': 'axis-q3fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'axis-q3fy24-index',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': [{'dimension': 1536,\n",
      "              'host': 'axis-q1fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q1fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'axis-q2fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q2fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'axis-q3fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q3fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n",
      "Index 'axis-q1fy24-index' exists.\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all existing indexes\n",
    "indexes = pc.list_indexes()\n",
    "print(indexes)\n",
    "# Check if a specific index exists\n",
    "index_name = \"axis-q1fy24-index\"\n",
    "if index_name in indexes[0]['name']:\n",
    "    print(f\"Index '{index_name}' exists.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all existing indexes\n",
    "# indexes = pc.list_indexes()\n",
    "pinecone.list_indexes().names()# \n",
    "index_names = [i['name'] for i in pc.list_indexes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q1fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q1fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q1fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n",
      "axis-q3fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q3fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q3fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n",
      "axis-q2fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q2fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q2fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "index_names = [i['name'] for i in pc.list_indexes()]\n",
    "\n",
    "# create separate serverless pinecone index for each index in index_set\n",
    "for item in vec_index_list:\n",
    "    # print(item)\n",
    "    if item not in index_names:\n",
    "        # print(item)\n",
    "        # create index\n",
    "        pc.create_index(\n",
    "            name=item,\n",
    "            dimension=1536,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\",\n",
    "            )\n",
    "        )\n",
    "        pc_index_dict[item] = pc.Index(item)\n",
    "        print(f'{item} created successfully')\n",
    "        print(pc.describe_index(name=item))\n",
    "    else:\n",
    "        pc_index_dict[item] = pc.Index(item)\n",
    "        print(f'{item} exists and is loaded successfully')\n",
    "        print(pc.describe_index(name=item))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index axis-bank exists; loaded and initialised successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-bank-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-bank',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use namespaces and metadata in a single index\n",
    "\n",
    "index_names = [i['name'] for i in pc.list_indexes()]\n",
    "\n",
    "new_index = 'axis-bank'\n",
    "# create single serverless pinecone index for each index in index_set\n",
    "if new_index not in index_names:\n",
    "    # print(item)\n",
    "    # create index\n",
    "    pc.create_index(\n",
    "        name=new_index,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "    pc_index = pc.Index(new_index)\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    print(f'Index {new_index} created and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))\n",
    "else:\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    pc_index = pc.Index(new_index)\n",
    "    print(f'Index {new_index} exists; loaded and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'fin_index' not in pc.list_indexes():\n",
    "#     # create index\n",
    "#     pc.create_index(\n",
    "#         name=\"fin-index\",\n",
    "#         dimension=1536,\n",
    "#         metric=\"cosine\",\n",
    "#         spec=ServerlessSpec(\n",
    "#             cloud=\"aws\",\n",
    "#             region=\"us-east-1\",\n",
    "#         )\n",
    "#     )\n",
    "#     print('finIndex created successfully')\n",
    "#     print(pc.describe_index(name=\"fin-index\"))\n",
    "#     # initialize index\n",
    "#     fin_index = pc.Index('fin-index')\n",
    "# else:\n",
    "#     fin_index = pc.Index('fin-index')\n",
    "#     print('finIndex loaded successfully')\n",
    "#     print(pc.describe_index(name=\"fin-index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24'],\n",
       " dict_keys(['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names, doc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delte index \n",
    "pc.delete_index(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index test created and initialised successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'test-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'test',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "new_index = 'test'\n",
    "# create single serverless pinecone index for each index in index_set\n",
    "if new_index not in index_names:\n",
    "    # print(item)\n",
    "    # create index\n",
    "    pc.create_index(\n",
    "        name=new_index,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "    pc_index = pc.Index(new_index)\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    print(f'Index {new_index} created and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))\n",
    "else:\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    pc_index = pc.Index(new_index)\n",
    "    print(f'Index {new_index} exists; loaded and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:01<00:00,  8.91it/s]\n",
      "Upserted vectors: 100%|██████████| 10/10 [00:03<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize index\n",
    "temp_index = pc.Index('test')\n",
    "# initialize pinecone vector store\n",
    "# metadata_filters = {\n",
    "#         'quarter': 'q1',\n",
    "#         'fiscal': 'fy24',\n",
    "#     }\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=temp_index,\n",
    "    namespace = 'test')\n",
    "    # metadata_filters = metadata_filters)\n",
    "# create storage context with pinecone vector store\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# create vector store index with documents and storage context\n",
    "item = VectorStoreIndex.from_documents(\n",
    "    doc_dict['axis-q1fy24'],\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, qtr, fiscal in zip(doc_names, quarter, year):\n",
    "    metadata = {\n",
    "        'quarter': qtr,\n",
    "        'fiscal': fiscal,\n",
    "    }\n",
    "    vector_store = PineconeVectorStore(\n",
    "        pinecone_index=pc_index,\n",
    "        metadata)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = axis_index.as_query_engine(similarity_top_k=15, node_postprocessors=[reranker])\n",
    "\n",
    "\n",
    "    rerank = FlagEmbeddingReranker(model='BAAT/bge-reranker-large', top_n=5)\n",
    "    # reranker = FlagEmbeddingReranker(model='BAAT/bge-reranker-large', top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parser and get nodes for text and summary for tables\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes, objects = noder_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_index = VectorStoreIndex(nodes=base_nodes+objects)\n",
    "\n",
    "# store vector index to disk\n",
    "\n",
    "query_engine = axis_index.as_query_engine(similarity_top_k=15, node_postprocessors=[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank = FlagEmbeddingReranker(model='BAAT/bge-reranker-large', top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
