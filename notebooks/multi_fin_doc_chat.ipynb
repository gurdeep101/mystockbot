{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found\n"
     ]
    }
   ],
   "source": [
    "# check for llamaparse key\n",
    "LLAMAPARSE_API_KEY = os.environ.get('LLAMAPARSE_API_KEY')\n",
    "if LLAMAPARSE_API_KEY is not None:\n",
    "    print('API key found')\n",
    "else:\n",
    "    print('Check for API key in environment variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufr-q1fy24.pdf', 'ufr-q3fy24.pdf', 'ufr-q2fy24.pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of files over which to prep\n",
    "file_list = [file for file in os.listdir('../data') if file.startswith('ufr')]\n",
    "file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(3, 11), match='-q1fy24.'>\n",
      "<re.Match object; span=(4, 10), match='q1fy24'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'q1fy24'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "\n",
    "re_dash_to_dot = re.compile(r\"-([^\\.]+)\\.\")\n",
    "print(re.search(re_dash_to_dot, file_list[0]))\n",
    "print(re.search(pattern, file_list[0]))\n",
    "re.search(pattern, file_list[0]).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of variables over which to construct the indexes\n",
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "doc_names = ['axis-'+re.search(pattern, file).group() for file in file_list]\n",
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24-index', 'axis-q3fy24-index', 'axis-q2fy24-index']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of variables over which to construct the indexes\n",
    "# positive loobehind assertion and positive lookahead assertion in regex to get filename\n",
    "pattern = r\"(?<=-)\\w+(?=\\.)\"\n",
    "vec_index_list = ['axis-'+re.search(pattern, file).group()+'-index' for file in file_list]\n",
    "vec_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fy24', 'fy24', 'fy24']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\\w{4}(?=\\.)\"\n",
    "year = [re.search(pattern, file).group() for file in file_list]\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q1', 'q3', 'q2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(?<=-)\\w{2}\"\n",
    "quarter = [re.search(pattern, file).group() for file in file_list]\n",
    "quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate parser\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMAPARSE_API_KEY,\n",
    "    result_type=\"markdown\", # or text\n",
    "    num_workers=4, # for multiple files\n",
    "    verbose=True,\n",
    "    language=\"en\", # default is english\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename as metadata\n",
    "file_extractor = {\".pdf\": parser}\n",
    "filename_fn = lambda filename: {\"file_name\": filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ufr-q1fy24.pdf', 'ufr-q3fy24.pdf', 'ufr-q2fy24.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufr-q1fy24.pdf axis-q1fy24 q1 fy24\n",
      "ufr-q3fy24.pdf axis-q3fy24 q3 fy24\n",
      "ufr-q2fy24.pdf axis-q2fy24 q2 fy24\n"
     ]
    }
   ],
   "source": [
    "for file, doc_name, qtr, yr in zip(file_list, doc_names, quarter, year):\n",
    "    print(file, doc_name, qtr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f9ea6848-8df9-420b-a878-566926859c67\n",
      "Started parsing the file under job_id cd6f681a-7cae-49ce-9c99-2afc2c77e5d0\n",
      "Started parsing the file under job_id 4860ecd4-2e72-4f99-bbb8-7ccac1c37ee2\n"
     ]
    }
   ],
   "source": [
    "# read in docs\n",
    "doc_dict = {}\n",
    "\n",
    "for file, doc_name, qtr, yr in zip(file_list, doc_names, quarter, year):\n",
    "    reader = SimpleDirectoryReader(\n",
    "        input_files=['../data/' + file],\n",
    "        file_extractor=file_extractor,\n",
    "        # filename_as_id=True,\n",
    "        file_metadata=filename_fn,\n",
    "        )\n",
    "    doc = reader.load_data()\n",
    "    for i in doc:\n",
    "        i.metadata={\n",
    "            'file_descr':f'Axis bank quarterly earnings report for {re.search(pattern, file).group()} ',\n",
    "            'financial_year': yr,\n",
    "            'quarter':qtr,\n",
    "                }\n",
    "        # i.metadata['file_descr']=str(f'Axis bank quarterly earnings report for {re.search(pattern, file).group()} '),\n",
    "        # i.metadata['financial year']=str(yr),\n",
    "        # i.metadata['quarter']=str(qtr),\n",
    "    doc_dict[doc_name] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_dict['axis-q1fy24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(variable, expected_length):\n",
    "    try:\n",
    "        if len(variable)==len(expected_length):\n",
    "            print('All files parsed')\n",
    "        else:\n",
    "            raise ValueError(f'Number of files parse is not equal to {len(expected_length)}')\n",
    "    except ValueError as e:\n",
    "        print(f'Caught Exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files parsed\n"
     ]
    }
   ],
   "source": [
    "check_length(doc_dict, file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more imports\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    "    )\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate llm and markdown parser\n",
    "llm = OpenAI(model='gpt-3.5-turbo-0125', temperature=0.1)\n",
    "node_parser=MarkdownElementNodeParser(llm=llm)\n",
    "storage_context = StorageContext.from_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Local Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/axis_qr_index\n",
      "data path exists\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(f'../data/axis_qr_index')\n",
    "\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)\n",
    "    print(data_path)\n",
    "    print('data path created')\n",
    "else:\n",
    "    print(data_path)\n",
    "    print('data path exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 4415.68it/s]\n",
      " 27%|██▋       | 4/15 [00:06<00:19,  1.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m documents \u001b[38;5;241m=\u001b[39m doc_dict[doc]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# run parser and get nodes for text and summary for tables\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43mnode_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m base_nodes, objects \u001b[38;5;241m=\u001b[39m node_parser\u001b[38;5;241m.\u001b[39mget_nodes_and_objects(nodes)\n\u001b[1;32m      8\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex(nodes\u001b[38;5;241m=\u001b[39mbase_nodes\u001b[38;5;241m+\u001b[39mobjects, storage_context\u001b[38;5;241m=\u001b[39mstorage_context)\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/node_parser/interface.py:76\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[0;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m doc_id_to_document \u001b[38;5;241m=\u001b[39m {doc\u001b[38;5;241m.\u001b[39mid_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m     74\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[0;32m---> 76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m             node\u001b[38;5;241m.\u001b[39mref_doc_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mref_doc_id \u001b[38;5;129;01min\u001b[39;00m doc_id_to_document\n\u001b[1;32m     82\u001b[0m         ):\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/node_parser/relational/base_element.py:120\u001b[0m, in \u001b[0;36mBaseElementNodeParser._parse_nodes\u001b[0;34m(self, nodes, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m nodes_with_progress \u001b[38;5;241m=\u001b[39m get_tqdm_iterable(nodes, show_progress, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes_with_progress:\n\u001b[0;32m--> 120\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     all_nodes\u001b[38;5;241m.\u001b[39mextend(nodes)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_nodes\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/node_parser/relational/markdown_element.py:32\u001b[0m, in \u001b[0;36mMarkdownElementNodeParser.get_nodes_from_node\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     30\u001b[0m table_elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_table_elements(elements)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# extract summaries over table elements\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_table_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_elements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# convert into nodes\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# will return a list of Nodes and Index Nodes\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nodes_from_elements(elements, node\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/node_parser/relational/base_element.py:198\u001b[0m, in \u001b[0;36mBaseElementNodeParser.extract_table_summaries\u001b[0;34m(self, elements)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TableOutput(summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(response_txt), columns\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    194\u001b[0m summary_jobs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    195\u001b[0m     _get_table_output(table_context, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummary_query_str)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m table_context \u001b[38;5;129;01min\u001b[39;00m table_context_list\n\u001b[1;32m    197\u001b[0m ]\n\u001b[0;32m--> 198\u001b[0m summary_outputs \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_jobs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msummary_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element, summary_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(elements, summary_outputs):\n\u001b[1;32m    204\u001b[0m     element\u001b[38;5;241m.\u001b[39mtable_output \u001b[38;5;241m=\u001b[39m summary_output\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/selectors.py:566\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop over the doc_list dictionary to parse the documents, construct vector index and store to disk\n",
    "for doc in doc_dict.keys():\n",
    "    # print(doc)\n",
    "    documents = doc_dict[doc]\n",
    "    # run parser and get nodes for text and summary for tables\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "    index = VectorStoreIndex(nodes=base_nodes+objects, storage_context=storage_context)\n",
    "    index.set_index_id(doc)\n",
    "    index.storage_context.persist(persist_dir=f'../data/axis_qr_index')\n",
    "    print(f'{doc} indexed and stored successfully to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded index axis-q1fy24 from local storage\n",
      "loaded index axis-q3fy24 from local storage\n",
      "loaded index axis-q2fy24 from local storage\n"
     ]
    }
   ],
   "source": [
    "# load stored index \n",
    "local_index= {}\n",
    "for name in doc_names:   \n",
    "    storage_context=StorageContext.from_defaults(\n",
    "        persist_dir=f'../data/axis_qr_index')\n",
    "    cur_index=load_index_from_storage(storage_context, index_id=name)\n",
    "    local_index[name]=cur_index\n",
    "    print(f'loaded index {name} from local storage')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://docs.llamaindex.ai/en/stable/module_guides/storing/customization/\n",
    "# # loop over the variable list and document dictionary to parse the nodes and construct indexes\n",
    "# for file_list_item, vec_index_list_item in zip(file_list, vec_index_list):\n",
    "    \n",
    "#     # store vector index to disk\n",
    "#     data_path = Path(f'../data/axis_qr_index/{vec_index_list_item}')\n",
    "#     # print(data_path)\n",
    "#     if not data_path.exists():\n",
    "#         Path.mkdir(data_path, parents=True, exist_ok=True)\n",
    "#         # print(data_path)\n",
    "    \n",
    "#     documents = doc_list[file_list_item]\n",
    "#     # run parser and get nodes for text and summary for tables\n",
    "#     nodes = node_parser.get_nodes_from_documents(documents)\n",
    "#     base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "#     index = VectorStoreIndex(nodes=base_nodes+objects, storage_context=storage_context)\n",
    "    \n",
    "#     index.storage_context.persist(persist_dir=data_path)\n",
    "#     print(f'{file_list_item} indexed and stored successfully to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indexing on Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurdeep/miniconda3/envs/streamchat/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# vector store imports\n",
    "# !pip install llama-index-vector-stores-pinecone\n",
    "# !pip install pinecone-client\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pc = Pinecone()\n",
    "\n",
    "# dictionary of indexes\n",
    "pc_index_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': [{'dimension': 1536,\n",
      "              'host': 'axis-q1fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q1fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'axis-q2fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q2fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'axis-bank-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-bank',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'test-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'test',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'dimension': 1536,\n",
      "              'host': 'axis-q3fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'axis-q3fy24-index',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n",
      "Index 'axis-q1fy24-index' exists.\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all existing indexes\n",
    "indexes = pc.list_indexes()\n",
    "print(indexes)\n",
    "# Check if a specific index exists\n",
    "index_name = \"axis-q1fy24-index\"\n",
    "if index_name in indexes[0]['name']:\n",
    "    print(f\"Index '{index_name}' exists.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all existing indexes\n",
    "# indexes = pc.list_indexes()\n",
    "# pinecone.list_indexes().names()# \n",
    "# index_names = [i['name'] for i in pc.list_indexes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q1fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q1fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q1fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n",
      "axis-q3fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q3fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q3fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n",
      "axis-q2fy24-index exists and is loaded successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-q2fy24-index-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-q2fy24-index',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "index_names = [i['name'] for i in pc.list_indexes()]\n",
    "\n",
    "# create separate serverless pinecone index for each index in index_set; i.e. quarterly result\n",
    "for item in vec_index_list:\n",
    "    # print(item)\n",
    "    if item not in index_names:\n",
    "        # print(item)\n",
    "        # create index\n",
    "        pc.create_index(\n",
    "            name=item,\n",
    "            dimension=1536,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\",\n",
    "            )\n",
    "        )\n",
    "        pc_index_dict[item] = pc.Index(item)\n",
    "        print(f'{item} created successfully')\n",
    "        print(pc.describe_index(name=item))\n",
    "    else:\n",
    "        pc_index_dict[item] = pc.Index(item)\n",
    "        print(f'{item} exists and is loaded successfully')\n",
    "        print(pc.describe_index(name=item))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'fin_index' not in pc.list_indexes():\n",
    "#     # create index\n",
    "#     pc.create_index(\n",
    "#         name=\"fin-index\",\n",
    "#         dimension=1536,\n",
    "#         metric=\"cosine\",\n",
    "#         spec=ServerlessSpec(\n",
    "#             cloud=\"aws\",\n",
    "#             region=\"us-east-1\",\n",
    "#         )\n",
    "#     )\n",
    "#     print('finIndex created successfully')\n",
    "#     print(pc.describe_index(name=\"fin-index\"))\n",
    "#     # initialize index\n",
    "#     fin_index = pc.Index('fin-index')\n",
    "# else:\n",
    "#     fin_index = pc.Index('fin-index')\n",
    "#     print('finIndex loaded successfully')\n",
    "#     print(pc.describe_index(name=\"fin-index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24'],\n",
       " dict_keys(['axis-q1fy24', 'axis-q3fy24', 'axis-q2fy24']))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_names, doc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delte index \n",
    "pc.delete_index(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index test exists; loaded and initialised successfully as test_index\n",
      "{'dimension': 1536,\n",
      " 'host': 'test-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'test',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "new_index = 'test'\n",
    "index_names = [i['name'] for i in pc.list_indexes()]\n",
    "\n",
    "# create single serverless pinecone index for each index in index_set\n",
    "if new_index not in index_names:\n",
    "    # print(item)\n",
    "    # create index\n",
    "    pc.create_index(\n",
    "        name=new_index,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "    test_index = pc.Index(new_index)\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    print(f'Index {new_index} created and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))\n",
    "else:\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    test_index = pc.Index(new_index)\n",
    "    print(f'Index {new_index} exists; loaded and initialised successfully as {new_index}_index')\n",
    "    print(pc.describe_index(name=new_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "\n",
      "\u001b[A\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:01<00:00,  7.02it/s]\n",
      "\n",
      "\u001b[A\n",
      "Upserted vectors: 100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize index\n",
    "# temp_index = pc.Index('test')\n",
    "\n",
    "# initialize pinecone vector store\n",
    "# metadata_filters = {\n",
    "#         'quarter': 'q1',\n",
    "#         'fiscal': 'fy24',\n",
    "#     }\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=test_index,\n",
    "    namespace = 'axis bank')\n",
    "    # metadata_filters = metadata_filters)\n",
    "# create storage context with pinecone vector store\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# create vector store index with documents and storage context\n",
    "item = VectorStoreIndex.from_documents(\n",
    "    doc_dict['axis-q1fy24'],\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index axis-bank exists; loaded and initialised successfully\n",
      "{'dimension': 1536,\n",
      " 'host': 'axis-bank-a0ad14b.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'axis-bank',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use namespaces and metadata in a single index for a bank\n",
    "\n",
    "index_names = [i['name'] for i in pc.list_indexes()]\n",
    "\n",
    "new_index = 'axis-bank'\n",
    "# create single serverless pinecone index for each index in index_set\n",
    "if new_index not in index_names:\n",
    "    # print(item)\n",
    "    # create index\n",
    "    pc.create_index(\n",
    "        name=new_index,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "    axis_index = pc.Index(new_index)\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    print(f'Index {new_index} created and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))\n",
    "else:\n",
    "    # pc_index_dict[new_index] = pc.Index(new_index)\n",
    "    axis_index = pc.Index(new_index)\n",
    "    print(f'Index {new_index} exists; loaded and initialised successfully')\n",
    "    print(pc.describe_index(name=new_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Upserted vectors: 100%|██████████| 10/10 [00:00<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis-q1fy24 upserted into a separate namespace\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreIndex' object has no attribute 'upsert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m PineconeVectorStore(\n\u001b[1;32m      4\u001b[0m     pinecone_index\u001b[38;5;241m=\u001b[39maxis_index,\n\u001b[1;32m      5\u001b[0m     namespace\u001b[38;5;241m=\u001b[39mdoc)\n\u001b[1;32m      6\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(vector_store\u001b[38;5;241m=\u001b[39mvector_store)\n\u001b[0;32m----> 7\u001b[0m axis_index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m upserted into a separate namespace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/base.py:145\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[1;32m    138\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[1;32m    139\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     transformations,\n\u001b[1;32m    141\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    143\u001b[0m )\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:75\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     69\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m embed_model_from_settings_or_context(Settings, service_context)\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/base.py:94\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m---> 94\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:308\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    301\u001b[0m     node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mEMBED) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[1;32m    302\u001b[0m ):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot build index from nodes with no content. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure all nodes have content.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:280\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/core/indices/vector_store/base.py:234\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[1;32m    233\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[0;32m--> 234\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node, new_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nodes_batch, new_ids):\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# NOTE: remove embedding from node to avoid duplication\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/streamchat/lib/python3.12/site-packages/llama_index/vector_stores/pinecone/base.py:393\u001b[0m, in \u001b[0;36mPineconeVectorStore.add\u001b[0;34m(self, nodes, **add_kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     ids\u001b[38;5;241m.\u001b[39mappend(node_id)\n\u001b[1;32m    392\u001b[0m     entries\u001b[38;5;241m.\u001b[39mappend(entry)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pinecone_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m(\n\u001b[1;32m    394\u001b[0m     entries,\n\u001b[1;32m    395\u001b[0m     namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamespace,\n\u001b[1;32m    396\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_kwargs,\n\u001b[1;32m    398\u001b[0m )\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreIndex' object has no attribute 'upsert'"
     ]
    }
   ],
   "source": [
    "for doc in doc_names:\n",
    "    # print(doc)\n",
    "    vector_store = PineconeVectorStore(\n",
    "        pinecone_index=axis_index,\n",
    "        namespace=doc)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    axis_index = VectorStoreIndex.from_documents(doc_dict[doc], storage_context=storage_context)\n",
    "    print(f'{doc} upserted into a separate namespace')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = FlagEmbeddingReranker(model='BAAI/bge-reranker-large', top_n=5)\n",
    "query_engine = index.as_query_engine(similarity_top_k=15, node_postprocessors=[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query engine tools with namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subquestion uqry engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
